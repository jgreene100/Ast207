{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ead61d1",
   "metadata": {
    "editable": true,
    "id": "4ead61d1",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Basic Statistics (Part 3)\n",
    "\n",
    "**Prerequisite**\n",
    "\n",
    "* $\\texttt{numpy}$ and $\\texttt{matplotlib}$.\n",
    "* Basic Statistics (Part 1 and 2)\n",
    "\n",
    "**New skills**\n",
    "\n",
    "* Probability notation and basic rules\n",
    "* Likelihood functions\n",
    "* Fitting a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d21bd55",
   "metadata": {
    "executionInfo": {
     "elapsed": 1200,
     "status": "ok",
     "timestamp": 1736645191970,
     "user": {
      "displayName": "Jared Siegel",
      "userId": "02704458627269853296"
     },
     "user_tz": -540
    },
    "id": "5d21bd55"
   },
   "outputs": [],
   "source": [
    "# Let's start with importing our packages\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We can beautify our plots by changing the matplotlib settings a little\n",
    "plt.rcParams['font.size'] = 18\n",
    "matplotlib.rcParams['axes.linewidth'] = 2\n",
    "matplotlib.rcParams['font.family'] = \"serif\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86cb28f",
   "metadata": {
    "editable": true,
    "id": "b86cb28f",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Part 1: probability functions\n",
    "\n",
    "We recently learned how to draw random numbers using $\\texttt{python}$ from Gaussian and Poisson distributions. Let's briefly review those skills.\n",
    "\n",
    "**Exercise 1**\n",
    "\n",
    "Draw 100 random numbers from a Gaussian distribution (with $\\sigma=1$ and $\\mu=0$) and plot the numbers in a histogram. On the same plot, repeat this experiment with 1000 and 10000 random draws. For each histogram, set `bins=30`, `range=[-4,4]`, `density=False`.\n",
    "\n",
    "Repeat your experiments on a second plot but now set `density=True`.\n",
    "\n",
    "Be sure to label your plots.\n",
    "\n",
    "*Bonus:* try using `for` loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "DVqPD78wPVpS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 979
    },
    "executionInfo": {
     "elapsed": 1385,
     "status": "ok",
     "timestamp": 1736645193352,
     "user": {
      "displayName": "Jared Siegel",
      "userId": "02704458627269853296"
     },
     "user_tz": -540
    },
    "id": "DVqPD78wPVpS",
    "outputId": "6e269d48-7a3e-41df-9045-ae50a8730722"
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5H6mYq50QVlO",
   "metadata": {
    "id": "5H6mYq50QVlO"
   },
   "source": [
    "**Exercise 2**\n",
    "\n",
    "Based on your plots, what does `density=True` and `density=False` do? What do you notice about the shape of the histogram as the number of random draws increases?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1c95a7-e63b-43ad-ba37-c3013e19cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VE7LQgK_SIib",
   "metadata": {
    "id": "VE7LQgK_SIib"
   },
   "source": [
    "---\n",
    "If there was a mathematical function that described that shape, we would no longer need to draw random numbers to understand the Guassian distribution. Instead, we could ask our function what numbers are likely and what numbers are unlikely.\n",
    "\n",
    "Fortunately, we know the function that describes the histogram of Gaussian random variables. It is called the Gaussian Probability Density Function (PDF):\n",
    "$$p(x) = \\frac{1}{\\sqrt{2\\pi} \\sigma} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$$\n",
    "\n",
    "**Exercise 3**\n",
    "\n",
    "Write a function for the Gaussian pdf: `def gaussian_pdf(x, mu, sigma)` that returns `p(x)`. Then plot the Gaussian pdf for `-4 < x < 4` alongside a histogram of random draws from the Gaussian distribution (with `density=True`). Repeat this process for $\\sigma = 0.5, 1.0$ (all with $\\mu = 0$).\n",
    "\n",
    "How many random draws do you need for the histogram to closely match `p(x)`? Does `p(x)` match the histogram if we instead set `density=False`?\n",
    "\n",
    "*Bonus:* use for loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jKvQgkNxQG3V",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1736645193352,
     "user": {
      "displayName": "Jared Siegel",
      "userId": "02704458627269853296"
     },
     "user_tz": -540
    },
    "id": "jKvQgkNxQG3V"
   },
   "outputs": [],
   "source": [
    "def gaussian_pdf(x, mu, sigma):\n",
    "    # your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7147af99",
   "metadata": {
    "id": "7147af99"
   },
   "source": [
    "# Part 2: fitting models to data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7rKBKOPRFi0b",
   "metadata": {
    "id": "7rKBKOPRFi0b"
   },
   "source": [
    "## Linear fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640c8cc7",
   "metadata": {
    "id": "640c8cc7"
   },
   "source": [
    "Let's revist the data on football players from earlier. We already saw that height and weight are correlated in the data (taller players tend to weight more). While we can clearly see the trend 'by eye,' is there a way to describe this correlation mathematically? For example, we may want to ask: \"what is the typical weight of players who are 6 feet tall?\"\n",
    "\n",
    "In astronomy, we often find ourselves asking questions like that. For example, how does the size of a star depend on it's brightness? or how does the shape of a galaxy depend on its age?\n",
    "\n",
    "In this section, we will learn how to find the mathemtical function that best describes a set of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7Ja1Sn7QHhvu",
   "metadata": {
    "id": "7Ja1Sn7QHhvu"
   },
   "source": [
    "Run the code below to load in the height and weights from the football player database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc64394-8f47-4140-ad87-0a79cd5ba99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load in the data\n",
    "import os\n",
    "from google.colab import drive\n",
    "from astropy.table import Table\n",
    "\n",
    "drive.mount('/content/drive/')\n",
    "os.chdir('/content/drive/Shareddrives/AST207/data')\n",
    "\n",
    "cat = Table.read('./players_age.csv')\n",
    "\n",
    "height = cat['height_inches']\n",
    "weight = cat['weight']\n",
    "\n",
    "height = np.array(height)\n",
    "weight = np.array(weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "J73150NRD08B",
   "metadata": {
    "id": "J73150NRD08B"
   },
   "source": [
    "The simplist relation between two variables `x` and `y` is the linear function:\n",
    "$$ y = m * x + b $$\n",
    "in our case, `x` is a player's height and `y` is the player's weight.\n",
    "\n",
    "**Exercise 4**\n",
    "\n",
    "Make the function `def linear(x,m,b)` that returns `y=m*x+b`. For `65 < x < 80` plot `linear(x, m, b)` alongside the observed heights and weights. Choose `m,b` such that the line best matches the observed data.\n",
    "\n",
    "Be sure to include labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earpzPqwGwZX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "executionInfo": {
     "elapsed": 932,
     "status": "ok",
     "timestamp": 1736645198701,
     "user": {
      "displayName": "Jared Siegel",
      "userId": "02704458627269853296"
     },
     "user_tz": -540
    },
    "id": "earpzPqwGwZX",
    "outputId": "f8608a09-e688-46c6-b88f-47a0da11dcbc"
   },
   "outputs": [],
   "source": [
    "def linear(x,m,b):\n",
    "  # your answer here\n",
    "\n",
    "# continue your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RPpMaGZzIc49",
   "metadata": {
    "id": "RPpMaGZzIc49"
   },
   "source": [
    "Finding values of `m,b` (the slope and intercept of our linear function) by hand wasn't too difficult but we have a few problems:\n",
    "\n",
    "\n",
    "1.   How do we convince our friends that we found the **best** values of `m,b`?\n",
    "2.   What if we have a function with lots of variables? Then finding the best by hand is no longer feasible.\n",
    "\n",
    "Thankfully, we don't have the find the best values by hand, we can ask our computers to help us. To have the computer find the best fitting line to the data, we'll follow a two step process:\n",
    "\n",
    "\n",
    "1.   Define a function that tells us how well our line matches the data. Let's call this our *objective function*.\n",
    "2.   Find the values of `m,b` that optimize our objective function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rQgvbZ0hK_7o",
   "metadata": {
    "id": "rQgvbZ0hK_7o"
   },
   "source": [
    "The simplist objective function would be to calculate the difference between our model's prediction for a player's weight given their height and the player's actual weight. If we calculate the difference between the model and the data for all the players, we'll know how closely we match the data. Mathematically this looks like:\n",
    "\n",
    "$$ \\mathrm{Simple~Objective~Function}(m,b)  = | \\mathrm{linear}(x_1,m,b) - y_1 | + | \\mathrm{linear}(x_2,m,b) - y_2 | + \\dots $$\n",
    "\n",
    "the \"$\\dots$\" means that we sum the difference between the model and the data for all the players in the table. The \"| |\" mean we are taking the absolute value (for example $| -1 |=1$).\n",
    "\n",
    "This simple function is close but let's make two small changes:\n",
    "1. Let's consider the **fractional** difference between the model prediction and the observed data (this will make sure we can fit data will small and large numbers easily).\n",
    "2. Let's take the square of the difference instead of absolute value. This is a common convention and will help us later on in the class.\n",
    "\n",
    "Now our final objective function is:\n",
    "\n",
    "$$ \\mathrm{Objective~Function}(m,b)  =  \\frac{[ \\mathrm{linear}(x_1,m,b) - y_1 )]^2}{|y_1|} + \\frac{[ \\mathrm{linear}(x_2,m,b) - y_2 )]^2}{|y_2|}  + \\dots $$\n",
    "\n",
    "(this objective function is commonly known as $\\chi^2$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YwWcFI8n7bZn",
   "metadata": {
    "id": "YwWcFI8n7bZn"
   },
   "source": [
    "**Exercise 5**\n",
    "\n",
    "Write a function that calculates the \"Objective Function\" for a given set of `x` and `y` data and the two parameters `m,b` of the linear function. Your function should have the form: `def objective_function(x,y,m,b)`\n",
    "\n",
    "As a test, `objective_function(x=height,y=weight,m=10,b=-500)` should return `6216.87`\n",
    "\n",
    "Hint: use `np.abs` to take the absolute value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ZpprNO-JqM-",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1736645198701,
     "user": {
      "displayName": "Jared Siegel",
      "userId": "02704458627269853296"
     },
     "user_tz": -540
    },
    "id": "1ZpprNO-JqM-"
   },
   "outputs": [],
   "source": [
    "def objective_function(x,y,m,b):\n",
    "    # your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iArHdiqO8cge",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1736645198701,
     "user": {
      "displayName": "Jared Siegel",
      "userId": "02704458627269853296"
     },
     "user_tz": -540
    },
    "id": "iArHdiqO8cge",
    "outputId": "ae7ace0d-bd85-4fe7-ac22-a85c22db0a89"
   },
   "outputs": [],
   "source": [
    "# test your function:\n",
    "objective_function(x=height,y=weight,m=10,b=-500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fWfw7338E75",
   "metadata": {
    "id": "3fWfw7338E75"
   },
   "source": [
    "**Exercise 6**\n",
    "\n",
    "Use your `objective_function` to search for good values of `m,b`. Using `for` loops, calculate `objective_function` for $0<m<20$ and $-1000<b<0$. For each combination of `b,m` plot `b` vs. `m` on a scatter plot with the color set by `simple_objective_function(x,y,m,b)`. For an example of a scatter plot with the points colored by a third parameter, see the [`numpy_and_plotting.ipynb` notebook](https://jgreene100.github.io/Ast207/docs/intro_python/numpy_and_plotting.html). Try 50 values of `b` and 50 values of `m` (it should run in less than a second). For ease of reading, plot `np.log10` of the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "kjGasX_9_P7u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1736645198993,
     "user": {
      "displayName": "Jared Siegel",
      "userId": "02704458627269853296"
     },
     "user_tz": -540
    },
    "id": "kjGasX_9_P7u",
    "outputId": "d70e3adf-b0b7-4b52-c612-986ccc434cba"
   },
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Eod7OchiAHFs",
   "metadata": {
    "id": "Eod7OchiAHFs"
   },
   "source": [
    "**Exercise 7**\n",
    "\n",
    "From your grid search above, find the values of `m,b` that yield the lowest `simple_objective_function`. Plot the linear function using these parameters alongside the football data and your by-band linear function. Be sure to label your plot.\n",
    "\n",
    "Hint: try using `np.argmin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "DRT7xjOUAY2M",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "executionInfo": {
     "elapsed": 648,
     "status": "ok",
     "timestamp": 1736645201114,
     "user": {
      "displayName": "Jared Siegel",
      "userId": "02704458627269853296"
     },
     "user_tz": -540
    },
    "id": "DRT7xjOUAY2M",
    "outputId": "874ea1ba-b927-4e1b-b8d6-84c0fbf66729"
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01186f06",
   "metadata": {
    "id": "01186f06"
   },
   "source": [
    "## Fitting astronomical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9lBjCpXGI7Z",
   "metadata": {
    "id": "a9lBjCpXGI7Z"
   },
   "source": [
    "Earlier, we looked at data from the Gaia space telescope. Gaia carefully observes the positions and properties of stars in our galaxy. The code below loads in the Gaia data for all stars within 15 parsec of the Sun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "N--lnW26GIPv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1770,
     "status": "ok",
     "timestamp": 1736645202879,
     "user": {
      "displayName": "Jared Siegel",
      "userId": "02704458627269853296"
     },
     "user_tz": -540
    },
    "id": "N--lnW26GIPv",
    "outputId": "1df0ac64-cc26-42a7-a20d-e47eb54fb4cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Let's load in the data\n",
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "os.chdir('/content/drive/Shareddrives/AST207/data')\n",
    "\n",
    "# path to the table\n",
    "path = 'gaia_15pc.csv'\n",
    "\n",
    "# loading the table; this function assumes a 'comma separated file (aka csv)'\n",
    "gaia = pd.read_csv(path)\n",
    "\n",
    "# simple errors\n",
    "gaia.loc[:,'color']     = gaia.gmag - gaia.rmag\n",
    "gaia.loc[:,'color_err'] = 0.04\n",
    "gaia.loc[:,'teff_err']  = 10. # K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q8wWsnWBHWI0",
   "metadata": {
    "id": "q8wWsnWBHWI0"
   },
   "source": [
    "**Exercise 8**\n",
    "\n",
    "In a previous activity, we searched for which properties of a star are correlated (like how football players heights and weights are correlated). Let's revisit that activity here. Below, plot `teff` versus `color` for the Gaia data (`teff` is the temperature of the star and `color` is the difference between the stars' `g` and `r` magnitudes). Be sure to label your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412f662c-0aea-4eaf-b445-fc2a7a4326ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your plot here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f002006",
   "metadata": {
    "id": "4f002006"
   },
   "source": [
    "Cool! We have a clear observational result: color and temperature of a star are strongly correlated.\n",
    "\n",
    "However, we still don't know *how* color and temperature are related. Is the relation linear, quadratic, or perhaps much more complex? Answering this question will greatly increase our understanding of the stars in our catalog (it will also help our theorist friends try to *explain* what's happening here)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae31df59",
   "metadata": {
    "id": "ae31df59"
   },
   "source": [
    "**Exercise 9**\n",
    "\n",
    "Like we did for the football data, fit the `teff` and `color` data with a linear function. Use the \"grid search\" method we used for the football data. Try fitting the data by hand first to choose appropriate ranges of `m,b` to search.\n",
    "\n",
    "Print out the best fit `m,b` and plot the best-fit line against the observed data.\n",
    "\n",
    "Hint: the slope (`m`) will be small. Try `m = -1e-4` to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "toBXyfAQKE23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4623,
     "status": "ok",
     "timestamp": 1736645208078,
     "user": {
      "displayName": "Jared Siegel",
      "userId": "02704458627269853296"
     },
     "user_tz": -540
    },
    "id": "toBXyfAQKE23",
    "outputId": "6fcb5d6b-6071-492b-c3b6-ad6d4fc75de0"
   },
   "outputs": [],
   "source": [
    "# Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebrpV9BLnjt",
   "metadata": {
    "id": "9ebrpV9BLnjt"
   },
   "source": [
    "**We just fit a model to astronomical data!** This is a critical tool in modern astronomy. But so far, we can only find the best solution by a time consuming \"grid search.\" Let's find a better way.\n",
    "\n",
    "Many algorithms have been developed to find the parameters that minimize a function (our grid search is one example). Let's use `scipy.optimize.minimize`.\n",
    "\n",
    "**Exercise 10**\n",
    "\n",
    "Run the code below to use `scipy.optimize.minimize`. Then plot the best fit linear function from `scipy.optimize.minimize` alongside the observed data and your \"grid search\" fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8rPBrHG-K87c",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1736645208079,
     "user": {
      "displayName": "Jared Siegel",
      "userId": "02704458627269853296"
     },
     "user_tz": -540
    },
    "id": "8rPBrHG-K87c"
   },
   "outputs": [],
   "source": [
    "def general_objective_function(theta, fn, x, y):\n",
    "\n",
    "  y_model = fn(x,*theta)\n",
    "\n",
    "  return np.sum(np.power(y-y_model,2) / np.abs(y) )\n",
    "\n",
    "out = scipy.optimize.minimize(general_objective_function, [-1e-4, 2], bounds = [[-1e-3,0], [0,10]], args = (linear, gaia.teff, gaia.color) )\n",
    "m_fit, b_fit = out.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "G8PcjWwNOxdI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1736645208079,
     "user": {
      "displayName": "Jared Siegel",
      "userId": "02704458627269853296"
     },
     "user_tz": -540
    },
    "id": "G8PcjWwNOxdI",
    "outputId": "52be0907-a993-426e-e5c8-2361eb55a603"
   },
   "outputs": [],
   "source": [
    "# Your plot here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5d91fa-d447-4a19-8482-4e0f665303f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2G8wcrXBST5u",
   "metadata": {
    "id": "2G8wcrXBST5u"
   },
   "source": [
    "We can now perform a linear fit and even can do it quicky using `scipy`. However, the above plots show that a linear fit is not a great match to the data. So what is?\n",
    "\n",
    "Fortunately, `general_objective_function` (which we provided for the activity above) allows us to change the function we are fitting...\n",
    "\n",
    "**Exercise 11**\n",
    "\n",
    "Let's try a model where color is *inversely* proportional to temperature:\n",
    "$$ \\mathrm{color} = m / T + b $$\n",
    "Write a function `def inverse(x, m, b)` that returns the inverse function. Then use `scipy` to find the best fit parameters. Plot the best fit inverse function alongside the observed data and the best fit linear function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "lrE-kqA2UTO3",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1736645208079,
     "user": {
      "displayName": "Jared Siegel",
      "userId": "02704458627269853296"
     },
     "user_tz": -540
    },
    "id": "lrE-kqA2UTO3"
   },
   "outputs": [],
   "source": [
    "def inverse(x, m, b):\n",
    "  # your code\n",
    "\n",
    "# use scipy to find the best fit parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ozWFrg9OU01t",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1736645208079,
     "user": {
      "displayName": "Jared Siegel",
      "userId": "02704458627269853296"
     },
     "user_tz": -540
    },
    "id": "ozWFrg9OU01t",
    "outputId": "c3cabdf0-22e5-45b7-a76c-e4f4b8fab09f"
   },
   "outputs": [],
   "source": [
    "# Your plot"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1dxjcFug9Fnia8XiKDM3Ul3dybW13UBVu",
     "timestamp": 1735445775064
    },
    {
     "file_id": "https://github.com/jgreene100/Ast207/blob/main/book/docs/stats/more_stats.ipynb",
     "timestamp": 1735445755623
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
